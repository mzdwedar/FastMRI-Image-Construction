import logging
import hydra
from omegaconf import DictConfig
from pytorch_lightning import Trainer
from torch.utils.data import DataLoader
import mlflow
from mlflow.tracking import MlflowClient
from urllib.parse import urlparse
from src.data import FastMRITransform, InferenceCustomDataset, FastMRICustomDataset
from src.model import UnetModel
from pathlib import Path
from hydra.utils import to_absolute_path

class TorchPredictor:
    def __init__(self, preprocessor, model):
        self.preprocessor = preprocessor
        self.model = model
        self.model.eval()
    
    def __call__(self, batch):
        scores = self.model.predict(batch)

        return {"results": scores}
    
    def get_preprocessor(self):
        return self.preprocessor
    
    @classmethod
    def from_checkpoint(cls, checkpoint_path):
        # metadata = checkpoint.get_metadata()
        preprocessor = FastMRITransform()
        model = UnetModel.load_from_checkpoint(checkpoint_path) # pylint: disable=no-value-for-parameter

        return cls(preprocessor=preprocessor, model=model)

def get_best_run_id(cfg: DictConfig) -> str:
    """
    Retrieve the best run ID from an MLflow experiment based on a specified metric.
    Args:
        cfg (DictConfig): Configuration object containing experiment details, including:
            - trainer.train.experiment_name: The name of the experiment to search.
            - trainer.checkpoint.mode: The mode for sorting the metric ('min' or 'max').
            - trainer.train.metric: The name of the metric to evaluate.
    Returns:
        str: The run ID of the best run based on the specified metric.
    Raises:
        ValueError: If the specified experiment is not found or if no runs are found for the experiment.
    """
    experiment = mlflow.get_experiment_by_name(cfg.trainer.train.experiment_name)
    if experiment is None:
        raise ValueError(f"Experiment {cfg.trainer.train.experiment_name} not found")
    
    experiment_id = experiment.experiment_id

    # decide sort order based on metric mode (min or max)
    metric_mode = cfg.trainer.checkpoint.get("mode", "min")
    sort_order = "ASC" if metric_mode == "min" else "DESC"

    sorted_run_ids = mlflow.search_runs(
        experiment_ids=[experiment_id],
        order_by=[f"metrics.{cfg.trainer.train.metric} {sort_order}"],
    )

    if sorted_run_ids.empty:
        raise ValueError("No runs found for this experiment")
    
    best_run_id = sorted_run_ids.iloc[0].run_id
    logging.info(f"Best run id: {best_run_id}")

    return best_run_id

def get_best_checkpoint(run_id: str, checkpoint_subdir: str = "checkpoints") -> str:
    """
    Get the best checkpoint path from a specific MLflow run (local storage).

    Args:
        run_id (str): ID of the run to get the best checkpoint from.
        checkpoint_subdir (str): Subdirectory where checkpoints are stored.

    Returns:
        str: Path to the best checkpoint file.
    """
    # Get artifact URI for the run
    client = MlflowClient()

    # List artifacts in the checkpoint folder
    artifacts = client.list_artifacts(run_id, path=checkpoint_subdir)
    if not artifacts:
        raise FileNotFoundError(f"No artifacts found in '{checkpoint_subdir}' for run {run_id}")

    # Take the first checkpoint (assuming save_top_k=1)
    best_ckpt_artifact = artifacts[0]

    # For local artifacts, the 'path' is relative to the run's artifact URI
    artifact_uri = client.get_run(run_id).info.artifact_uri
    local_path = f"{artifact_uri}/{best_ckpt_artifact.path}"

    logging.info(f"Best checkpoint for run {run_id} is at: {local_path}")
    return local_path

def predict_fn(trainer, data: DataLoader, predictor: TorchPredictor):
    """
    Perform inference on a single data sample using the provided predictor.

    Args:
        data (Any): Input data sample to be processed.
        predictor (TorchPredictor): An instance of TorchPredictor containing the model and preprocessor.

    Returns:
        Any: The prediction results from the model.
    
    Raises:
        Exception: If there is an issue with data preprocessing or model prediction.
    """

    predictions = trainer.predict(predictor.model, data)

    return predictions

@hydra.main(version_base=None, config_path='../configs', config_name='config')
def main(cfg: DictConfig):
    """
    Perform batch inference on a dataset using a trained model.

    Args:
        cfg (DictConfig): Configuration object containing settings for 
                          data path, model, and trainer parameters.

    Returns:
        List: A list of predictions generated by the model for the input data.
    
    Raises:
        Exception: If there is an issue with loading the dataset, model, or during prediction.
    """
    data_path = to_absolute_path(cfg.trainer.predict.batch.data_path)
    dataset = FastMRICustomDataset(data_path, transform=FastMRITransform(mask_func=None))
    data_loader = DataLoader(dataset, batch_size=8, shuffle=False)
    run_id = get_best_run_id(cfg)
    checkpoint_path = get_best_checkpoint(run_id)
    predictor = TorchPredictor.from_checkpoint(checkpoint_path)

    trainer = Trainer(accelerator=cfg.trainer.accelerator,
                      devices=cfg.trainer.gpus
                    )
    
    predictions = predict_fn(trainer, data_loader, predictor)

    return predictions


if __name__ == "__main__":
    main() # pylint: disable=no-value-for-parameter

